"""Main entry point for SCC vulnerability ingestion cron job"""

import logging
import asyncio
import sys
from datetime import datetime
from firestore_datastore import Datastore
from ingestion_service import IngestionService
import config

# Configure logging
logging.basicConfig(
    level=getattr(logging, config.LOG_LEVEL),
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler(f'ingestion_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
    ]
)
logger = logging.getLogger(__name__)


async def main():
    """Main execution function"""
    start_time = datetime.now()
    logger.info("=" * 80)
    logger.info("SCC Vulnerability Ingestion Job Started")
    logger.info(f"Start Time: {start_time.isoformat()}")
    logger.info(f"Datastore: Firestore")
    logger.info("=" * 80)
    
    datastore = None
    
    try:
        # Create datastore
        datastore = Datastore()
        
        # Create ingestion service
        service = IngestionService(datastore)
        
        # Run ingestion (use parallel for better performance with 60k+ rows)
        stats = await service.ingest_vulnerabilities_parallel()
        
        # Get datastore statistics
        datastore_stats = await datastore.get_statistics()
        
        # Log results
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        logger.info("=" * 80)
        logger.info("SCC Vulnerability Ingestion Job Completed")
        logger.info(f"End Time: {end_time.isoformat()}")
        logger.info(f"Duration: {duration:.2f} seconds")
        logger.info(f"Findings Fetched: {stats['total_fetched']}")
        logger.info(f"Vulnerabilities Upserted: {stats['total_upserted']}")
        logger.info(f"Projects Mapped: {stats['projects_mapped']}")
        logger.info(f"Batches Processed: {stats.get('batches_processed', 'N/A')}")
        logger.info(f"Throughput: {stats['total_upserted'] / duration:.2f} records/second")
        logger.info(f"Datastore Stats: {datastore_stats}")
        logger.info("=" * 80)
        
        return 0
        
    except Exception as e:
        logger.error(f"Fatal error during ingestion: {e}", exc_info=True)
        return 1
        
    finally:
        # Cleanup
        if datastore:
            await datastore.close()
            logger.info("Datastore connection closed")


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
