"""Service for ingesting and enriching vulnerability data"""

import logging
from typing import List, Dict, Any
import asyncio
from firestore_datastore import Datastore
from scc_client import SCCClient
import config

logger = logging.getLogger(__name__)


class IngestionService:
    """Service for ingesting vulnerability data from SCC"""
    
    def __init__(self, datastore: Datastore):
        self.datastore = datastore
        self.scc_client = SCCClient()
        self.project_mapping = {}
        logger.info("Initialized IngestionService")
    
    async def load_project_mapping(self):
        """Load project mapping from datastore"""
        logger.info("Loading project mapping...")
        self.project_mapping = await self.datastore.get_project_mapping()
        logger.info(f"Loaded {len(self.project_mapping)} project mappings")
    
    def enrich_vulnerability(self, vulnerability: Dict[str, Any]) -> Dict[str, Any]:
        """
        Enrich vulnerability with appcode and lob from project mapping.
        
        Args:
            vulnerability: Vulnerability data
            
        Returns:
            Enriched vulnerability data
        """
        project_id = vulnerability.get('project_id')
        
        if project_id and project_id in self.project_mapping:
            mapping = self.project_mapping[project_id]
            vulnerability['appcode'] = mapping.get('appcode', 'unknown')
            vulnerability['lob'] = mapping.get('lob', 'unknown')
        else:
            vulnerability['appcode'] = 'unknown'
            vulnerability['lob'] = 'unknown'
            if project_id:
                logger.debug(f"No mapping found for project: {project_id}")
        
        return vulnerability
    
    async def ingest_vulnerabilities(self) -> Dict[str, Any]:
        """
        Main ingestion process:
        1. Load project mapping
        2. Fetch findings from SCC
        3. Enrich with appcode/lob
        4. Batch upsert to datastore
        
        Returns:
            Statistics dictionary
        """
        logger.info("Starting vulnerability ingestion...")
        
        # Load project mapping first
        await self.load_project_mapping()
        
        # Fetch findings from SCC (generator for memory efficiency)
        findings_generator = self.scc_client.fetch_vulnerability_findings()
        
        # Process in batches
        batch = []
        total_fetched = 0
        total_upserted = 0
        
        for finding in findings_generator:
            # Enrich finding
            enriched_finding = self.enrich_vulnerability(finding)
            batch.append(enriched_finding)
            total_fetched += 1
            
            # When batch is full, upsert to datastore
            if len(batch) >= config.BATCH_SIZE:
                upserted = await self.datastore.upsert_vulnerabilities(batch)
                total_upserted += upserted
                logger.info(f"Progress: Fetched {total_fetched}, Upserted {total_upserted}")
                batch = []
        
        # Upsert remaining batch
        if batch:
            upserted = await self.datastore.upsert_vulnerabilities(batch)
            total_upserted += upserted
        
        logger.info(f"Ingestion complete: Fetched {total_fetched}, Upserted {total_upserted}")
        
        return {
            'total_fetched': total_fetched,
            'total_upserted': total_upserted,
            'projects_mapped': len(self.project_mapping)
        }
    
    async def ingest_vulnerabilities_parallel(self) -> Dict[str, Any]:
        """
        Parallel ingestion process using ThreadPoolExecutor.
        Fetches from SCC in one thread while processing batches in parallel.
        
        Returns:
            Statistics dictionary
        """
        logger.info("Starting parallel vulnerability ingestion...")
        
        # Load project mapping first
        await self.load_project_mapping()
        
        # Fetch all findings (for parallel processing)
        logger.info("Fetching all findings from SCC...")
        findings = list(self.scc_client.fetch_vulnerability_findings())
        total_fetched = len(findings)
        logger.info(f"Fetched {total_fetched} findings from SCC")
        
        # Split into batches
        batches = [findings[i:i + config.BATCH_SIZE] 
                   for i in range(0, len(findings), config.BATCH_SIZE)]
        
        logger.info(f"Split into {len(batches)} batches of size {config.BATCH_SIZE}")
        
        # Process batches in parallel
        total_upserted = 0
        
        async def process_batch(batch_findings: List[Dict[str, Any]]) -> int:
            """Process a single batch"""
            enriched = [self.enrich_vulnerability(f) for f in batch_findings]
            return await self.datastore.upsert_vulnerabilities(enriched)
        
        # Process batches with limited concurrency
        semaphore = asyncio.Semaphore(config.MAX_WORKERS)
        
        async def process_with_semaphore(batch):
            async with semaphore:
                return await process_batch(batch)
        
        tasks = [process_with_semaphore(batch) for batch in batches]
        results = await asyncio.gather(*tasks)
        
        total_upserted = sum(results)
        
        logger.info(f"Parallel ingestion complete: Fetched {total_fetched}, Upserted {total_upserted}")
        
        return {
            'total_fetched': total_fetched,
            'total_upserted': total_upserted,
            'projects_mapped': len(self.project_mapping),
            'batches_processed': len(batches)
        }
